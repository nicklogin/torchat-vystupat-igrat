{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала разберёмя с глаголом <i>торчать</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_vectors = np.load(\"torchat_context_vectors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2564, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchat_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим матрицу сходства по косинусной близости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_matrix = cosine_similarity(torchat_vectors, torchat_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то странные округления, на диагонали не всегда чистые единицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем лучше средствами SciPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean, cosine, pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    return 1 - cosine(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_matrix = squareform(pdist(torchat_vectors, metric=cosine_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2564, 2564)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinity_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как функция squareform используется для построения матрицы расстояний, а не близости, на главную диагональ она ставит нули. Заменим нули на единицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(affinity_matrix)):\n",
    "    affinity_matrix[i][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.18362963,  0.19143231, ..., -0.23330173,\n",
       "         0.50011109,  0.30826989],\n",
       "       [ 0.18362963,  1.        ,  0.15421649, ...,  0.02815803,\n",
       "         0.08029822,  0.05262811],\n",
       "       [ 0.19143231,  0.15421649,  1.        , ...,  0.01757288,\n",
       "         0.3454869 ,  0.31797122],\n",
       "       ...,\n",
       "       [-0.23330173,  0.02815803,  0.01757288, ...,  1.        ,\n",
       "        -0.10239787, -0.03999091],\n",
       "       [ 0.50011109,  0.08029822,  0.3454869 , ..., -0.10239787,\n",
       "         1.        ,  0.48480015],\n",
       "       [ 0.30826989,  0.05262811,  0.31797122, ..., -0.03999091,\n",
       "         0.48480015,  1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь используем модный алгоритм AffinityPropagation, как в статье тех крутых челов с Диалога:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AffinityPropagation имеет $O(T* n^2)$  сложность, поэтому сначала попробуем на небольшом подмножестве датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer1 = AffinityPropagation(affinity='precomputed', damping=0.99, max_iter=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer2 = AffinityPropagation(affinity='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affinity_matrix[:10,:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test_cluster_labels1 = clusterizer1.fit_predict(affinity_matrix[:100,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_cluster_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test_cluster_labels2 = clusterizer2.fit_predict(torchat_vectors[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9,  7,  0,  9,  7,  9,  4, 12,  1,  7, 10,  7, 10,  4,  9,  2,\n",
       "        7,  4, 12, 12,  3, 10,  7, 10,  7,  7,  4,  7,  9,  9, 10, 10,  9,\n",
       "        4,  4,  9, 10,  5, 10, 10, 12,  6,  9,  4,  7,  7,  7,  7,  9, 10,\n",
       "       10,  7,  7, 10, 10,  4,  8,  9, 10, 11, 10,  4,  4,  7,  7, 10, 12,\n",
       "       10, 12, 10, 12,  4, 10, 10, 10,  7,  7, 12, 10,  7,  7,  7,  9,  9,\n",
       "        7, 10,  7,  9,  7, 12, 12, 10,  9,  7, 12, 12,  4, 10, 13],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cluster_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torchat_labels = clusterizer1.fit_predict(affinity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько кластеров у нас получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(torchat_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И сколько объектов в каждом кластере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_labels = list(torchat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 36,\n",
       " 101: 35,\n",
       " 94: 25,\n",
       " 15: 6,\n",
       " 61: 18,\n",
       " 71: 30,\n",
       " 55: 23,\n",
       " 122: 22,\n",
       " 19: 16,\n",
       " 120: 35,\n",
       " 104: 26,\n",
       " 24: 38,\n",
       " 79: 10,\n",
       " 140: 35,\n",
       " 148: 25,\n",
       " 59: 7,\n",
       " 8: 34,\n",
       " 53: 6,\n",
       " 23: 45,\n",
       " 95: 26,\n",
       " 130: 50,\n",
       " 12: 39,\n",
       " 14: 7,\n",
       " 119: 23,\n",
       " 75: 52,\n",
       " 124: 14,\n",
       " 0: 17,\n",
       " 107: 21,\n",
       " 88: 18,\n",
       " 129: 10,\n",
       " 115: 23,\n",
       " 98: 14,\n",
       " 85: 12,\n",
       " 56: 10,\n",
       " 35: 9,\n",
       " 117: 40,\n",
       " 146: 25,\n",
       " 80: 32,\n",
       " 52: 20,\n",
       " 57: 30,\n",
       " 112: 18,\n",
       " 62: 18,\n",
       " 1: 20,\n",
       " 32: 20,\n",
       " 116: 64,\n",
       " 63: 44,\n",
       " 2: 4,\n",
       " 131: 10,\n",
       " 97: 15,\n",
       " 84: 33,\n",
       " 7: 29,\n",
       " 51: 13,\n",
       " 9: 15,\n",
       " 87: 18,\n",
       " 3: 36,\n",
       " 76: 17,\n",
       " 65: 19,\n",
       " 34: 31,\n",
       " 132: 37,\n",
       " 50: 30,\n",
       " 36: 15,\n",
       " 17: 10,\n",
       " 123: 43,\n",
       " 144: 11,\n",
       " 143: 40,\n",
       " 29: 14,\n",
       " 78: 19,\n",
       " 81: 5,\n",
       " 68: 10,\n",
       " 105: 17,\n",
       " 66: 24,\n",
       " 72: 18,\n",
       " 102: 16,\n",
       " 4: 9,\n",
       " 16: 8,\n",
       " 96: 10,\n",
       " 89: 13,\n",
       " 60: 11,\n",
       " 28: 13,\n",
       " 47: 4,\n",
       " 5: 5,\n",
       " 134: 37,\n",
       " 93: 21,\n",
       " 113: 27,\n",
       " 141: 31,\n",
       " 133: 11,\n",
       " 6: 6,\n",
       " 118: 10,\n",
       " 10: 32,\n",
       " 58: 8,\n",
       " 37: 6,\n",
       " 114: 11,\n",
       " 137: 29,\n",
       " 26: 16,\n",
       " 46: 25,\n",
       " 13: 14,\n",
       " 45: 25,\n",
       " 74: 16,\n",
       " 38: 32,\n",
       " 109: 11,\n",
       " 136: 5,\n",
       " 21: 11,\n",
       " 103: 14,\n",
       " 86: 17,\n",
       " 11: 6,\n",
       " 126: 7,\n",
       " 77: 12,\n",
       " 41: 15,\n",
       " 90: 12,\n",
       " 40: 17,\n",
       " 43: 11,\n",
       " 73: 4,\n",
       " 127: 14,\n",
       " 142: 11,\n",
       " 100: 6,\n",
       " 31: 6,\n",
       " 67: 23,\n",
       " 145: 8,\n",
       " 18: 7,\n",
       " 20: 18,\n",
       " 70: 9,\n",
       " 22: 7,\n",
       " 49: 7,\n",
       " 91: 17,\n",
       " 138: 12,\n",
       " 39: 10,\n",
       " 128: 4,\n",
       " 82: 7,\n",
       " 54: 10,\n",
       " 27: 6,\n",
       " 111: 8,\n",
       " 92: 11,\n",
       " 106: 7,\n",
       " 30: 2,\n",
       " 108: 5,\n",
       " 110: 4,\n",
       " 44: 4,\n",
       " 33: 8,\n",
       " 64: 8,\n",
       " 42: 3,\n",
       " 48: 6,\n",
       " 135: 6,\n",
       " 99: 6,\n",
       " 121: 4,\n",
       " 139: 4,\n",
       " 147: 15,\n",
       " 69: 3,\n",
       " 125: 7,\n",
       " 83: 2}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:torchat_labels.count(i) for i in torchat_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось много мелких кластеров, это не есть хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [[i for i in range(len(torchat_labels)) if torchat_labels[i] == label] for label in set(torchat_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('torchat.json', 'r', encoding='utf-8') as inp:\n",
    "    torchat_json = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_contexts_affinity_clusters = [[torchat_json[index][1] for index in cluster] for cluster in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 64 , 0.025 contexts covered\n",
      "1 52 , 0.0452 contexts covered\n",
      "2 50 , 0.0647 contexts covered\n",
      "3 45 , 0.0823 contexts covered\n",
      "4 44 , 0.0995 contexts covered\n",
      "5 43 , 0.1162 contexts covered\n",
      "6 40 , 0.1318 contexts covered\n",
      "7 40 , 0.1474 contexts covered\n",
      "8 39 , 0.1626 contexts covered\n",
      "9 38 , 0.1775 contexts covered\n",
      "10 37 , 0.1919 contexts covered\n",
      "11 37 , 0.2063 contexts covered\n",
      "12 36 , 0.2204 contexts covered\n",
      "13 36 , 0.2344 contexts covered\n",
      "14 35 , 0.248 contexts covered\n",
      "15 35 , 0.2617 contexts covered\n",
      "16 35 , 0.2754 contexts covered\n",
      "17 34 , 0.2886 contexts covered\n",
      "18 33 , 0.3015 contexts covered\n",
      "19 32 , 0.314 contexts covered\n",
      "20 32 , 0.3264 contexts covered\n",
      "21 32 , 0.3389 contexts covered\n",
      "22 31 , 0.351 contexts covered\n",
      "23 31 , 0.3631 contexts covered\n",
      "24 30 , 0.3748 contexts covered\n",
      "25 30 , 0.3865 contexts covered\n",
      "26 30 , 0.3982 contexts covered\n",
      "27 29 , 0.4095 contexts covered\n",
      "28 29 , 0.4208 contexts covered\n",
      "29 27 , 0.4314 contexts covered\n",
      "30 26 , 0.4415 contexts covered\n",
      "31 26 , 0.4516 contexts covered\n",
      "32 25 , 0.4614 contexts covered\n",
      "33 25 , 0.4711 contexts covered\n",
      "34 25 , 0.4809 contexts covered\n",
      "35 25 , 0.4906 contexts covered\n",
      "36 25 , 0.5004 contexts covered\n",
      "37 24 , 0.5098 contexts covered\n",
      "38 23 , 0.5187 contexts covered\n",
      "39 23 , 0.5277 contexts covered\n",
      "40 23 , 0.5367 contexts covered\n",
      "41 23 , 0.5456 contexts covered\n",
      "42 22 , 0.5542 contexts covered\n",
      "43 21 , 0.5624 contexts covered\n",
      "44 21 , 0.5706 contexts covered\n",
      "45 20 , 0.5784 contexts covered\n",
      "46 20 , 0.5862 contexts covered\n",
      "47 20 , 0.594 contexts covered\n",
      "48 19 , 0.6014 contexts covered\n",
      "49 19 , 0.6088 contexts covered\n",
      "50 18 , 0.6158 contexts covered\n",
      "51 18 , 0.6229 contexts covered\n",
      "52 18 , 0.6299 contexts covered\n",
      "53 18 , 0.6369 contexts covered\n",
      "54 18 , 0.6439 contexts covered\n",
      "55 18 , 0.6509 contexts covered\n",
      "56 18 , 0.658 contexts covered\n",
      "57 17 , 0.6646 contexts covered\n",
      "58 17 , 0.6712 contexts covered\n",
      "59 17 , 0.6778 contexts covered\n",
      "60 17 , 0.6845 contexts covered\n",
      "61 17 , 0.6911 contexts covered\n",
      "62 17 , 0.6977 contexts covered\n",
      "63 16 , 0.704 contexts covered\n",
      "64 16 , 0.7102 contexts covered\n",
      "65 16 , 0.7165 contexts covered\n",
      "66 16 , 0.7227 contexts covered\n",
      "67 15 , 0.7285 contexts covered\n",
      "68 15 , 0.7344 contexts covered\n",
      "69 15 , 0.7402 contexts covered\n",
      "70 15 , 0.7461 contexts covered\n",
      "71 15 , 0.752 contexts covered\n",
      "72 14 , 0.7574 contexts covered\n",
      "73 14 , 0.7629 contexts covered\n",
      "74 14 , 0.7683 contexts covered\n",
      "75 14 , 0.7738 contexts covered\n",
      "76 14 , 0.7793 contexts covered\n",
      "77 14 , 0.7847 contexts covered\n",
      "78 13 , 0.7898 contexts covered\n",
      "79 13 , 0.7949 contexts covered\n",
      "80 13 , 0.7999 contexts covered\n",
      "81 12 , 0.8046 contexts covered\n",
      "82 12 , 0.8093 contexts covered\n",
      "83 12 , 0.814 contexts covered\n",
      "84 12 , 0.8186 contexts covered\n",
      "85 11 , 0.8229 contexts covered\n",
      "86 11 , 0.8272 contexts covered\n",
      "87 11 , 0.8315 contexts covered\n",
      "88 11 , 0.8358 contexts covered\n",
      "89 11 , 0.8401 contexts covered\n",
      "90 11 , 0.8444 contexts covered\n",
      "91 11 , 0.8487 contexts covered\n",
      "92 11 , 0.853 contexts covered\n",
      "93 11 , 0.8573 contexts covered\n",
      "94 10 , 0.8612 contexts covered\n",
      "95 10 , 0.8651 contexts covered\n",
      "96 10 , 0.869 contexts covered\n",
      "97 10 , 0.8729 contexts covered\n",
      "98 10 , 0.8768 contexts covered\n",
      "99 10 , 0.8807 contexts covered\n",
      "100 10 , 0.8846 contexts covered\n",
      "101 10 , 0.8885 contexts covered\n",
      "102 10 , 0.8924 contexts covered\n",
      "103 10 , 0.8963 contexts covered\n",
      "104 9 , 0.8998 contexts covered\n",
      "105 9 , 0.9033 contexts covered\n",
      "106 9 , 0.9068 contexts covered\n",
      "107 8 , 0.9099 contexts covered\n",
      "108 8 , 0.913 contexts covered\n",
      "109 8 , 0.9161 contexts covered\n",
      "110 8 , 0.9193 contexts covered\n",
      "111 8 , 0.9224 contexts covered\n",
      "112 8 , 0.9255 contexts covered\n",
      "113 7 , 0.9282 contexts covered\n",
      "114 7 , 0.931 contexts covered\n",
      "115 7 , 0.9337 contexts covered\n",
      "116 7 , 0.9364 contexts covered\n",
      "117 7 , 0.9392 contexts covered\n",
      "118 7 , 0.9419 contexts covered\n",
      "119 7 , 0.9446 contexts covered\n",
      "120 7 , 0.9473 contexts covered\n",
      "121 7 , 0.9501 contexts covered\n",
      "122 6 , 0.9524 contexts covered\n",
      "123 6 , 0.9548 contexts covered\n",
      "124 6 , 0.9571 contexts covered\n",
      "125 6 , 0.9594 contexts covered\n",
      "126 6 , 0.9618 contexts covered\n",
      "127 6 , 0.9641 contexts covered\n",
      "128 6 , 0.9665 contexts covered\n",
      "129 6 , 0.9688 contexts covered\n",
      "130 6 , 0.9711 contexts covered\n",
      "131 6 , 0.9735 contexts covered\n",
      "132 6 , 0.9758 contexts covered\n",
      "133 5 , 0.9778 contexts covered\n",
      "134 5 , 0.9797 contexts covered\n",
      "135 5 , 0.9817 contexts covered\n",
      "136 5 , 0.9836 contexts covered\n",
      "137 4 , 0.9852 contexts covered\n",
      "138 4 , 0.9867 contexts covered\n",
      "139 4 , 0.9883 contexts covered\n",
      "140 4 , 0.9899 contexts covered\n",
      "141 4 , 0.9914 contexts covered\n",
      "142 4 , 0.993 contexts covered\n",
      "143 4 , 0.9945 contexts covered\n",
      "144 4 , 0.9961 contexts covered\n",
      "145 3 , 0.9973 contexts covered\n",
      "146 3 , 0.9984 contexts covered\n",
      "147 2 , 0.9992 contexts covered\n",
      "148 2 , 1.0 contexts covered\n"
     ]
    }
   ],
   "source": [
    "N = len(torchat_vectors)\n",
    "i = 0\n",
    "s = 0\n",
    "\n",
    "for cluster in sorted(torchat_contexts_affinity_clusters, key=len, reverse=True):\n",
    "    s += len(cluster)\n",
    "    x = round(s/N, 4)\n",
    "    print(i, len(cluster), f\", {x} contexts covered\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение размера кластера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.991, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые 103 кластера покрывают около 90% контекстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_contexts_affinity_clusters = sorted(torchat_contexts_affinity_clusters, key=len, reverse=True)\n",
    "\n",
    "with open('torchat_affinity_clusters_cosine.json','w',encoding='utf-8') as outp:\n",
    "    json.dump(torchat_contexts_affinity_clusters, outp, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dump in module json:\n",
      "\n",
      "dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "    Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "    ``.write()``-supporting file-like object).\n",
      "    \n",
      "    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "    instead of raising a ``TypeError``.\n",
      "    \n",
      "    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "    contain non-ASCII characters if they appear in strings contained in\n",
      "    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "    \n",
      "    If ``check_circular`` is false, then the circular reference check\n",
      "    for container types will be skipped and a circular reference will\n",
      "    result in an ``OverflowError`` (or worse).\n",
      "    \n",
      "    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "    in strict compliance of the JSON specification, instead of using the\n",
      "    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "    \n",
      "    If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "    object members will be pretty-printed with that indent level. An indent\n",
      "    level of 0 will only insert newlines. ``None`` is the most compact\n",
      "    representation.\n",
      "    \n",
      "    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "    you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "    \n",
      "    ``default(obj)`` is a function that should return a serializable version\n",
      "    of obj or raise TypeError. The default simply raises TypeError.\n",
      "    \n",
      "    If *sort_keys* is true (default: ``False``), then the output of\n",
      "    dictionaries will be sorted by key.\n",
      "    \n",
      "    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "    ``.default()`` method to serialize additional types), specify it with\n",
      "    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(json.dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резюме кластеризации:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 кластер - целиком про волосы и части тела, 1 контекст я успел заметить про одежду (торчали рукава), но преобладают волосы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 кластер - в основном про части тела"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем в 1 кластере контексты про волосы, во 2 в основном про части тела, в 3 - в основном про животных. Может и хорошее разделение, но в данной задаче нерелевантное. Впредь будем использовать алгоритмы с определяемым пользователем числом кластеров. Но напоследок ещё попробуем AffinityPropagation с Евклидовой близостью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterizer2 = AffinityPropagation(affinity='euclidean', damping=0.99, max_iter=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_labels2 = clusterizer2.fit_predict(torchat_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 261 , 0.1018 contexts covered\n",
      "1 204 , 0.1814 contexts covered\n",
      "2 195 , 0.2574 contexts covered\n",
      "3 166 , 0.3222 contexts covered\n",
      "4 159 , 0.3842 contexts covered\n",
      "5 141 , 0.4392 contexts covered\n",
      "6 135 , 0.4918 contexts covered\n",
      "7 95 , 0.5289 contexts covered\n",
      "8 95 , 0.5659 contexts covered\n",
      "9 90 , 0.601 contexts covered\n",
      "10 90 , 0.6361 contexts covered\n",
      "11 85 , 0.6693 contexts covered\n",
      "12 84 , 0.702 contexts covered\n",
      "13 80 , 0.7332 contexts covered\n",
      "14 78 , 0.7637 contexts covered\n",
      "15 67 , 0.7898 contexts covered\n",
      "16 60 , 0.8132 contexts covered\n",
      "17 59 , 0.8362 contexts covered\n",
      "18 57 , 0.8584 contexts covered\n",
      "19 46 , 0.8764 contexts covered\n",
      "20 41 , 0.8924 contexts covered\n",
      "21 34 , 0.9056 contexts covered\n",
      "22 27 , 0.9161 contexts covered\n",
      "23 26 , 0.9263 contexts covered\n",
      "24 21 , 0.9345 contexts covered\n",
      "25 17 , 0.9411 contexts covered\n",
      "26 17 , 0.9477 contexts covered\n",
      "27 17 , 0.9544 contexts covered\n",
      "28 15 , 0.9602 contexts covered\n",
      "29 13 , 0.9653 contexts covered\n",
      "30 11 , 0.9696 contexts covered\n",
      "31 8 , 0.9727 contexts covered\n",
      "32 7 , 0.9754 contexts covered\n",
      "33 7 , 0.9782 contexts covered\n",
      "34 6 , 0.9805 contexts covered\n",
      "35 6 , 0.9828 contexts covered\n",
      "36 5 , 0.9848 contexts covered\n",
      "37 5 , 0.9867 contexts covered\n",
      "38 4 , 0.9883 contexts covered\n",
      "39 3 , 0.9895 contexts covered\n",
      "40 2 , 0.9902 contexts covered\n",
      "41 2 , 0.991 contexts covered\n",
      "42 2 , 0.9918 contexts covered\n",
      "43 2 , 0.9926 contexts covered\n",
      "44 1 , 0.993 contexts covered\n",
      "45 1 , 0.9934 contexts covered\n",
      "46 1 , 0.9938 contexts covered\n",
      "47 1 , 0.9941 contexts covered\n",
      "48 1 , 0.9945 contexts covered\n",
      "49 1 , 0.9949 contexts covered\n",
      "50 1 , 0.9953 contexts covered\n",
      "51 1 , 0.9957 contexts covered\n",
      "52 1 , 0.9961 contexts covered\n",
      "53 1 , 0.9965 contexts covered\n",
      "54 1 , 0.9969 contexts covered\n",
      "55 1 , 0.9973 contexts covered\n",
      "56 1 , 0.9977 contexts covered\n",
      "57 1 , 0.998 contexts covered\n",
      "58 1 , 0.9984 contexts covered\n",
      "59 1 , 0.9988 contexts covered\n",
      "60 1 , 0.9992 contexts covered\n",
      "61 1 , 0.9996 contexts covered\n",
      "62 1 , 1.0 contexts covered\n"
     ]
    }
   ],
   "source": [
    "clusters2 = [[i for i in range(len(torchat_labels2)) if torchat_labels2[i] == label] for label in set(torchat_labels2)]\n",
    "\n",
    "N = len(torchat_vectors)\n",
    "i = 0\n",
    "s = 0\n",
    "\n",
    "for cluster in sorted(clusters2, key=len, reverse=True):\n",
    "    s += len(cluster)\n",
    "    x = round(s/N, 4)\n",
    "    print(i, len(cluster), f\", {x} contexts covered\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хмм-м-м, 62 кластеров - уже получше, а первые 21 покрывают 90% контекстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchat_contexts_affinity_clusters2 = [[torchat_json[index][1] for index in cluster] for cluster in clusters2]\n",
    "\n",
    "torchat_contexts_affinity_clusters2 = sorted(torchat_contexts_affinity_clusters2, key=len, reverse=True)\n",
    "\n",
    "with open('torchat_affinity_clusters_euclidean.json','w',encoding='utf-8') as outp:\n",
    "    json.dump(torchat_contexts_affinity_clusters2, outp, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут вообще получается что-то неинформативное, пока оставим AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
